<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en"><![endif]--><!--[if gt IE 8]><!--><html class="no-js" lang="en"><!--<![endif]--><html class="no-js" lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Learn how to build event-driven microservices with Apache Kafka, Kotlin, and Ktor | gamov.io</title><meta name="author" content="Viktor Gamov &lt;viktor@confluent.io&gt;, Anton Arhipov &lt;anton@jetbrains.com&gt;"><meta name="twitter:card" content="summary"><meta name="twitter:creator" content="@asciidoctor"><meta name="twitter:url" content="http://gamov.io/workshop/2021/03/30/ktor-kafka-2021.html"><meta name="twitter:title" content="Learn how to build event-driven microservices with Apache Kafka, Kotlin, and Ktor"><meta name="twitter:description" content="Table of content
Links
Prerequisites
Tutorial
Gradle build
Config files
Web application
Data classes
Streaming application
Infrastructure
How can I implement an average aggregation that implements incremental functions, namely count and sum?
Kafka Streams natively supports..."><link rel="stylesheet" href="/stylesheets/app.css"><script src="/javascripts/vendor/custom.modernizr.js"></script><link rel="shortcut icon" href="/images/favicon.ico"><link rel="author" href="/humans.txt"><link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"></head><body class="antialiased"><nav class="top-bar"><ul class="title-area"><li class="name"><h1><a href="/">Viktor Gamov</a></h1></li></ul><section class="top-bar-section"><ul class="right"><li class="divider"></li><li><a href="/posts.html"><span class="icon"><i class="fa fa-th-large"></i></span>&nbspBlog</a></li><li class="divider"></li><li><a href="https://www.youtube.com/ViktorGamov" target="_blank"><span class="icon"><i class="fa fa-youtube"></i></span>&nbspYouTube </a></li><li class="divider"></li><li><a href="https://speaking.gamov.io" target="_blank"><span class="icon"><i class="fa fa-slideshare"></i></span>&nbspMy Talks</a></li><li class="divider"></li><li><a href="https://github.com/gamussa" target="_blank"><span class="icon"><i class="fa fa-github"></i></span>&nbspGithub</a></li><li class="divider"></li><li><a href="https://twitter.com/gamussa" target="_blank"><span class="icon"><i class="fa fa-twitter"></i></span>&nbspTwitter</a></li><li class="divider"></li><li class="has-form"><a class="small button" href="http://enterprisewebbook.com">Enterprise Web Development</a></li></ul></section></nav><div class="row"><div class="large-12 column"><h1 class="header"><a href="http://gamov.io">Crash Course In Java Brain Surgery</a></h1><h6 class="subheader">insinuation and speculations: My thoughts about Java, HTML5, software development and IT in general</h6><hr></div></div><!--Main Page Content--><div class="row"><div id="content"><!--Main Blog Content--><div class="large-12 columns" role="content"></div><article><h2 class="header"><a href="/workshop/2021/03/30/ktor-kafka-2021.html">Learn how to build event-driven microservices with Apache Kafka, Kotlin, and Ktor</a></h2><h5 class="subheader">Written by&nbsp <a href="#">Viktor Gamov &lt;viktor@confluent.io&gt;, Anton Arhipov &lt;anton@jetbrains.com&gt;</a>&nbsp- <time class="pubdate" datetime="2021-03-30T00:00:00+00:00">Tuesday, March 30, 2021</time></h5><div class="row"><div class="large-12 columns text-left"><div id="toc" class="toc">
<div id="toctitle">Table of content</div>
<ul class="sectlevel1">
<li><a href="#links">Links</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#tutorial">Tutorial</a>
<ul class="sectlevel2">
<li><a href="#gradle-build">Gradle build</a></li>
<li><a href="#config-files">Config files</a></li>
<li><a href="#web-application">Web application</a>
<ul class="sectlevel3">
<li><a href="#data-classes">Data classes</a></li>
</ul>
</li>
<li><a href="#streaming-application">Streaming application</a></li>
</ul>
</li>
<li><a href="#infrastructure">Infrastructure</a></li>
</ul>
</div>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>How can I implement an average aggregation that implements incremental functions, namely count and sum?</p>
</div>
<div class="paragraph">
<p>Kafka Streams natively supports <em>incremental</em> aggregation functions, in which the aggregation result is updated based on the values captured by each window.
Incremental functions include <code>count</code>, <code>sum</code>, <code>min</code>, and <code>max</code>.
An average aggregation cannot be computed incrementally.
However, as this tutorial shows, it can be implemented by composing incremental functions, namely count and sum.
Consider a topic with events that represent ratings of movies.
In this tutorial, we&#8217;ll write a program that calculates and maintains a running average rating for each movie.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/ktor-kafka.png" alt="ktor kafka">
</div>
<div class="title">Figure 1. The Tutorial Architecture Overview</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="links"><a class="anchor" href="#links"></a>Links</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="https://gamov.dev/ktor-kafka">Self-link</a></p>
</li>
<li>
<p><a href="https://gamov.dev/ktor-kafka-git">Github repo with full example</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="prerequisites"><a class="anchor" href="#prerequisites"></a>Prerequisites</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ensure you install the following toolset on your computer:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://confluent.cloud">Confluent Cloud</a></p>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You should have your login and password information handy after you sign up for Confluent Cloud.
The <code>ccloud</code> init script will ask you for your login information.
</td>
</tr>
</table>
</div>
</li>
<li>
<p><a href="https://docs.confluent.io/current/cloud/cli/install.html">Confluent Cloud CLI</a></p>
</li>
<li>
<p>Docker (If you want to run locally)</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.docker.com/docker-for-mac/install/">install Docker Desktop for MacOS</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Git</p>
</li>
<li>
<p><a href="https://jdk.dev">Java 11 (or later)</a></p>
</li>
<li>
<p>Your favorite IDE or text editor</p>
<div class="ulist">
<ul>
<li>
<p>Personally, I recommend <a href="https://www.jetbrains.com/idea/">IntelliJ IDEA</a>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tutorial"><a class="anchor" href="#tutorial"></a>Tutorial</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To get started, make a new directory anywhere you&#8217;d like for this project:</p>
</div>
<div class="paragraph">
<p>First, create a Kotlin project with Kotlin DSL</p>
</div>
<div class="sect2">
<h3 id="gradle-build"><a class="anchor" href="#gradle-build"></a>Gradle build</h3>
<div class="listingblock">
<div class="title">build.gradle.kts</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">import org.jetbrains.kotlin.gradle.dsl.Coroutines
import org.jetbrains.kotlin.gradle.tasks.KotlinCompile

val logback_version: String by project
val ktor_version: String by project
val kotlin_version: String by project
val confluent_version: String by project
val ak_version: String by project

plugins {
    application
    kotlin("jvm") version "1.4.30"
}

group = "com.example"
version = "0.0.1-SNAPSHOT"

application {
    mainClassName = "io.ktor.server.netty.EngineMain"
}

repositories {
    mavenLocal()
    jcenter()
    maven ("https://packages.confluent.io/maven")
    maven ("https://kotlin.bintray.com/ktor")
    maven ("https://jitpack.io")
}

dependencies {
    implementation("org.apache.kafka:kafka-streams:2.7.0")

    implementation("io.confluent:kafka-json-schema-serializer:$confluent_version")
    implementation("io.confluent:kafka-streams-json-schema-serde:$confluent_version") {
        exclude("org.apache.kafka", "kafka-clients")
    }

    implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8:$kotlin_version")
    implementation("io.ktor:ktor-server-netty:$ktor_version")
    implementation("ch.qos.logback:logback-classic:$logback_version")
    implementation("io.ktor:ktor-server-core:$ktor_version")
    implementation("io.ktor:ktor-html-builder:$ktor_version")
    implementation("io.ktor:ktor-server-host-common:$ktor_version")
    implementation("io.ktor:ktor-jackson:$ktor_version")
    implementation("io.ktor:ktor-websockets:$ktor_version")

    implementation("com.github.gAmUssA:ktor-kafka:1913118fb3")

    testImplementation("io.ktor:ktor-server-tests:$ktor_version")
    testImplementation("org.apache.kafka:kafka-streams-test-utils:$ak_version")
}

tasks.withType&lt;KotlinCompile&gt;().configureEach {
    kotlinOptions.jvmTarget = "1.8"
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">gradle.properies</div>
<div class="content">
<pre class="nowrap">kotlin.code.style=official
org.gradle.parallel=true
org.gradle.caching=true
ktor_version=1.5.2
logback_version=1.2.1
kotlin_version=1.4.30
confluent_version=6.1.1
ak_version=2.7.0</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="config-files"><a class="anchor" href="#config-files"></a>Config files</h3>
<div class="listingblock">
<div class="title">application.conf</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-hocon hljs" data-lang="hocon">ktor {
  development = true

  deployment {
    port = 8080
    port = ${?PORT}
  }
  application {
    modules = [
      io.confluent.developer.ApplicationKt.module,
      io.confluent.developer.kstreams.RunningAverageKt.module
    ]
  }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">kafka.conf</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code>ktor {
  kafka {
    # Required connection configs for Kafka producer, consumer, and admin
    bootstrap.servers = ["server"]

    properties {
      security.protocol = SASL_SSL
      sasl.jaas.config = "org.apache.kafka.common.security.plain.PlainLoginModule     required username='user'     password='password';"
      sasl.mechanism = PLAIN
      # Required for correctness in Apache Kafka clients prior to 2.6
      client.dns.lookup = use_all_dns_ips
      # Best practice for Kafka producer to prevent data loss
      acks = all

      # Required connection configs for Confluent Cloud Schema Registry
      schema.registry.url = "sr_url"
      basic.auth.credentials.source = USER_INFO
      basic.auth.user.info = "key:pass"
    }
    consumer {
      group.id = "ktor-consumer"
      key.deserializer = org.apache.kafka.common.serialization.LongDeserializer
      value.deserializer = org.apache.kafka.common.serialization.DoubleDeserializer
    }
    producer {
      client.id = "ktor-producer"
      key.serializer = org.apache.kafka.common.serialization.LongSerializer
      value.serializer = io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer
    }
    streams {
      application.id = "ktor-stream"
      # TODO: cloud should be 3
      replication.factor = 3
      //cache.max.size.buffering = 1024
      cache.max.bytes.buffering = 0
      default.topic.replication.factor = 3
      //default.key.serde
      //default.value.serde
    }
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="web-application"><a class="anchor" href="#web-application"></a>Web application</h3>
<div class="paragraph">
<p>First, we create a view code that renders the UI using the kotlinx.html library. create the following file at <code>/src/main/kotlin/io/confluent/developer/Html.kt</code>.</p>
</div>
<div class="listingblock">
<div class="title">Html.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">package io.confluent.developer

import kotlinx.html.*
import kotlinx.html.dom.createHTMLDocument
import org.w3c.dom.Document

object Html {

    class TEMPLATE(consumer: TagConsumer&lt;*&gt;) :
        HTMLTag(
            "template", consumer, emptyMap(),
            inlineTag = true,
            emptyTag = false
        ), HtmlInlineTag

    fun FlowContent.template(block: TEMPLATE.() -&gt; Unit = {}) {
        TEMPLATE(consumer).visit(block)
    }

    fun TEMPLATE.li(classes: String? = null, block: LI.() -&gt; Unit = {}) {
        LI(attributesMapOf("class", classes), consumer).visit(block)
    }

    fun page(js: String, content: FlowContent.() -&gt; Unit = {}): HTML.() -&gt; Unit = {
        head {
            css("https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css")
            css("https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css")
            js("https://code.jquery.com/jquery-3.5.1.slim.min.js")
            js("https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js")

            js("/assets/$js")
            title("Ktor Kafka App")
        }

        body {
            div("container rounded") {
                content()
            }
        }
    }

    val indexHTML = page("index.js") {
        val movies = mapOf(
            362 to "Lethal Weapon",
            363 to "Guardians of the Galaxy",
            364 to "Se7en"
        )
        div("row") {
            form(
                action = "/rating",
                method = FormMethod.post
            ) {
                name = "myform"
                id = "myform"
                div("form-group row") {
                    label("col-4 col-form-label") {
                        htmlFor = "movieId"
                        +"Movie Title"
                    }
                    div("col-8") {
                        select("custom-select") {
                            name = "movieId"
                            id = "movieId"
                            for ((k, v) in movies) {
                                option {
                                    value = k.toString()
                                    +v
                                }
                            }
                        }
                    }
                }

                div("form-group row") {
                    label("col-4 col-form-label") {
                        htmlFor = "rating"
                        +"Rating"
                    }
                    div("col-8") {
                        select("custom-select") {
                            name = "rating"
                            id = "rating"
                            for (n in 10 downTo 1) {
                                option {
                                    value = n.toString()
                                    +"$n"
                                }
                            }
                        }
                    }
                }

                div("form-group row") {
                    div("offset-4 col-8") {
                        button(classes = "btn btn-primary", type = ButtonType.submit, name = "submit") {
                            +"Submit"
                        }

                    }
                }

            }
        }

        div("container") {
            id = "myAlert"
            div("alert alert-success alert-dismissible hide") {
                id = "myAlert2"
                role = "alert"
                +"Thank you for submitting your rating"
                button(type = ButtonType.button, classes = "close") {
                    attributes["data-dismiss"] = "alert"
                    span {
                        +"x"
                    }
                }
            }
        }


    }

    val index: Document = createHTMLDocument().html(block = indexHTML)

    fun HEAD.css(source: String) {
        link(source, LinkRel.stylesheet)
    }

    fun HEAD.js(source: String) {
        script(ScriptType.textJavaScript) {
            src = source
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>There&#8217;s some JavaScript that we need to include for this HTML thingy to work properly.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s add the following file: <code>/src/main/resources/META-INF/resources/assets/index.js</code> with the content&#8217;s as provided below:</p>
</div>
<div class="listingblock">
<div class="title">index.js</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-javascript hljs" data-lang="javascript">const wsProto = (window.location.protocol === 'https:') ? 'wss:' : 'ws:';
const wsBase = `${wsProto}//${window.location.hostname}:${window.location.port}`;

window.onload = function () {
    $(".alert").hide()
    let myForm = document.getElementById('myform');
    myForm.addEventListener('submit', function (event) {
        event.preventDefault();
        let formData = new FormData(myForm), result = {};

        for (let entry of formData.entries()) {
            result[entry[0]] = entry[1];
        }
        result = JSON.stringify(result)
        // console.log(result);

        let xhr = new XMLHttpRequest();

        xhr.open(myForm.method, myForm.action, true);
        xhr.setRequestHeader('Content-Type', 'application/json; charset=UTF-8');
        xhr.send(result);
        $(".alert").show()
    });

    let ws = new WebSocket(`${wsBase}/kafka`);
    ws.onmessage = function (event) {
        let data = JSON.parse(event.data);
        console.log(data)
    };

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>First, we set up a form listener to send the movie ratings to the web application. And secondly there&#8217;s a WebSocket channel that we open in order to receive the data from the backend.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s build the application backend now. Create the following file at <code>/src/main/kotlin/io/confluent/developer/Application.kt</code>.</p>
</div>
<div class="listingblock">
<div class="title">Application.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">import com.typesafe.config.Config
import com.typesafe.config.ConfigFactory.parseFile
import io.confluent.developer.Html.indexHTML
import io.confluent.developer.kstreams.Rating
import io.confluent.developer.kstreams.ratingTopicName
import io.confluent.developer.kstreams.ratingsAvgTopicName
import io.confluent.developer.ktor.buildProducer
import io.confluent.developer.ktor.createKafkaConsumer
import io.confluent.developer.ktor.send
import io.ktor.application.*
import io.ktor.features.*
import io.ktor.html.*
import io.ktor.http.*
import io.ktor.http.cio.websocket.*
import io.ktor.http.content.*
import io.ktor.jackson.*
import io.ktor.request.*
import io.ktor.response.*
import io.ktor.routing.*
import io.ktor.server.netty.*
import io.ktor.websocket.*
import org.apache.kafka.clients.consumer.KafkaConsumer
import org.apache.kafka.clients.producer.KafkaProducer
import java.io.File
import java.time.Duration

fun main(args: Array&lt;String&gt;): Unit = EngineMain.main(args)

fun Application.module(testing: Boolean = false) {

    //https://youtrack.jetbrains.com/issue/KTOR-2318
    val kafkaConfigPath = "src/main/resources/kafka.conf"

    install(ContentNegotiation) {
        jackson()
    }

    val config: Config = parseFile(File(kafkaConfigPath))
    val producer: KafkaProducer&lt;Long, Rating&gt; = buildProducer(config)

    install(WebSockets)
    routing {
        //region static assets location
        static("/assets") {
            resources("META-INF/resources/assets")
        }
        //endregion

        post("rating") {
            val rating = call.receive&lt;Rating&gt;()

            producer.send(ratingTopicName, rating.movieId, rating)

            data class Status(val message: String)
            call.respond(HttpStatusCode.Accepted, Status("Accepted"))
        }

        webSocket("/kafka") {
            val consumer: KafkaConsumer&lt;Long, Double&gt; = createKafkaConsumer(config, ratingsAvgTopicName)
            try {
                while (true) {
                    consumer.poll(Duration.ofMillis(100))
                        .forEach {
                            outgoing.send(
                                Frame.Text(
                                    """{
                                "movieId":${it.key()},
                                "rating":${it.value()}
                                }
                            """.trimIndent()
                                )
                            )
                        }
                }
            } finally {
                consumer.apply {
                    unsubscribe()
                    //close()
                }
                log.info("consumer for ${consumer.groupMetadata().groupId()} unsubscribed and closed...")
            }
        }
        get("/") {
            call.respondHtml(
                HttpStatusCode.OK,
                indexHTML
            )
        }
    }
}</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="data-classes"><a class="anchor" href="#data-classes"></a>Data classes</h4>
<div class="paragraph">
<p>Create a data class file at <code>src/main/kotlin/io/confluent/developer/kstreams/Rating.kt</code> for the stream of ratings:</p>
</div>
<div class="listingblock">
<div class="title">Rating.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">data class Rating(val movieId: Long = 1L, val rating: Double = 0.0)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, create data class file in <code>src/main/kotlin/io/confluent/developer/kstreams/Rating.kt</code> for the pair of counts and sums:</p>
</div>
<div class="listingblock">
<div class="title">CountAndSum.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">data class CountAndSum(var count: Long = 0L, var sum: Double = 0.0)</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
We&#8217;re going to use this record to store intermediate results.
The reason why we&#8217;re using json schema support in Schema Registry for this is that we can use <code>KafkaJsonSchemaSerde</code> to handle all our serialization needs.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="streaming-application"><a class="anchor" href="#streaming-application"></a>Streaming application</h3>
<div class="paragraph">
<p>Then create the following file at <code>/src/main/kotlin/io/confluent/developer/kstreams/RunningAverage.kt</code>.
Let&#8217;s take a close look at the <code>buildTopology()</code> method, which uses the Kafka Streams DSL.</p>
</div>
<div class="listingblock">
<div class="title">RunningAverage.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">import com.typesafe.config.Config
import com.typesafe.config.ConfigFactory
import io.confluent.developer.ktor.*
import io.confluent.kafka.schemaregistry.client.SchemaRegistryClientConfig.BASIC_AUTH_CREDENTIALS_SOURCE
import io.confluent.kafka.schemaregistry.client.SchemaRegistryClientConfig.USER_INFO_CONFIG
import io.confluent.kafka.streams.serdes.json.KafkaJsonSchemaSerde
import io.ktor.application.*
import io.ktor.server.netty.*
import org.apache.kafka.common.serialization.Serdes.*
import org.apache.kafka.common.utils.Bytes
import org.apache.kafka.streams.KafkaStreams
import org.apache.kafka.streams.KeyValue
import org.apache.kafka.streams.StreamsBuilder
import org.apache.kafka.streams.Topology
import org.apache.kafka.streams.kstream.*
import org.apache.kafka.streams.kstream.Grouped.with
import org.apache.kafka.streams.state.KeyValueStore
import java.io.File
import java.time.Duration
import java.util.*

const val ratingTopicName = "ratings"
const val ratingsAvgTopicName = "rating-averages"

fun Application.module(testing: Boolean = false) {

    lateinit var streams: KafkaStreams

    // load properties
    val kafkaConfigPath = "src/main/resources/kafka.conf"
    val config: Config = ConfigFactory.parseFile(File(kafkaConfigPath))
    val properties = effectiveStreamProperties(config)

    //region Kafka
    install(Kafka) {
        configurationPath = kafkaConfigPath
        topics = listOf(
            newTopic(ratingTopicName) {
                partitions = 3
                //replicas = 1 // for docker
                replicas = 3 // for cloud
            },
            newTopic(ratingsAvgTopicName) {
                partitions = 3
                //replicas = 1 // for docker
                replicas = 3 // for cloud
            }
        )
    }
    //endregion

    val streamsBuilder = StreamsBuilder()
    val topology = buildTopology(streamsBuilder, properties)
    //(topology.describe().toString())

    streams = streams(topology, config)

    environment.monitor.subscribe(ApplicationStarted) {
        streams.cleanUp()
        streams.start()
        log.info("Kafka Streams app is ready to roll...")
    }

    environment.monitor.subscribe(ApplicationStopped) {
        log.info("Time to clean up...")
        streams.close(Duration.ofSeconds(5))
    }
}

fun buildTopology( builder: StreamsBuilder, properties: Properties ): Topology {

    val ratingStream: KStream&lt;Long, Rating&gt; = ratingsStream(builder, properties)

    getRatingAverageTable(
        ratingStream,
        ratingsAvgTopicName,
        jsonSchemaSerde(properties, false)
    )
    return builder.build()
}

fun ratingsStream(builder: StreamsBuilder, properties: Properties): KStream&lt;Long, Rating&gt; {
return builder.stream( ratingTopicName, Consumed.with(Long(), jsonSchemaSerde(properties, false)) ) }

fun getRatingAverageTable( ratings: KStream&lt;Long, Rating&gt;, avgRatingsTopicName: String, countAndSumSerde: KafkaJsonSchemaSerde&lt;CountAndSum&gt; ): KTable&lt;Long, Double&gt; {

    // Grouping Ratings
    val ratingsById: KGroupedStream&lt;Long, Double&gt; = ratings
        .map { _, rating -&gt; KeyValue(rating.movieId, rating.rating) }
        .groupByKey(with(Long(), Double()))

    val ratingCountAndSum: KTable&lt;Long, CountAndSum&gt; = ratingsById.aggregate(
        { CountAndSum(0L, 0.0) },
        { _, value, aggregate -&gt;
            aggregate.count = aggregate.count + 1
            aggregate.sum = aggregate.sum + value
            aggregate
        },
        Materialized.with(Long(), countAndSumSerde)
    )

    val ratingAverage: KTable&lt;Long, Double&gt; = ratingCountAndSum.mapValues(
        { value -&gt; value.sum.div(value.count) },
        Materialized.`as`&lt;Long, Double, KeyValueStore&lt;Bytes, ByteArray&gt;&gt;("average-ratings")
            .withKeySerde(LongSerde())
            .withValueSerde(DoubleSerde())
    )

    // persist the result in topic
    val stream = ratingAverage.toStream()
    //stream.peek { key, value -&gt; println("$key:$value") }
    stream.to(avgRatingsTopicName, producedWith&lt;Long, Double&gt;())
    return ratingAverage
}

inline fun &lt;reified V&gt; jsonSchemaSerde( properties: Properties, isKeySerde: Boolean ): KafkaJsonSchemaSerde&lt;V&gt; {
    val schemaSerde = KafkaJsonSchemaSerde(V::class.java)
    val crSource = properties[BASIC_AUTH_CREDENTIALS_SOURCE]
    val uiConfig = properties[USER_INFO_CONFIG]

    val map = mutableMapOf(
        "schema.registry.url" to properties["schema.registry.url"]
    )
    crSource?.let {
        map[BASIC_AUTH_CREDENTIALS_SOURCE] = crSource
    }
    uiConfig?.let {
        map[USER_INFO_CONFIG] = uiConfig
    }
    schemaSerde.configure(map, isKeySerde)
    return schemaSerde;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To calculate the running average, we need to capture the sum of ratings and counts as part of the same aggregating operation.</p>
</div>
<div class="listingblock">
<div class="title">Compute count and sum in a single aggregation step and emit <code>&lt;count,sum&gt;</code> tuple as aggregation result values.</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">val ratingCountAndSum: KTable&lt;Long, CountAndSum&gt; = ratingsById.aggregate(
        { CountAndSum(0L, 0.0) },
        { _, value, aggregate -&gt;
            aggregate.count = aggregate.count + 1
            aggregate.sum = aggregate.sum + value
            aggregate
        },
        Materialized.with(Long(), countAndSumSerde)
    )</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Compute average for each tuple.</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">val ratingAverage: KTable&lt;Long, Double&gt; = ratingCountAndSum.mapValues(
        { value -&gt; value.sum.div(value.count) },
        Materialized.`as`&lt;Long, Double, KeyValueStore&lt;Bytes, ByteArray&gt;&gt;("average-ratings")
            .withKeySerde(LongSerde())
            .withValueSerde(DoubleSerde())
    )</code></pre>
</div>
</div>
<div class="paragraph">
<p>This pattern can also be applied to compute a windowed average or to compose other functions.</p>
</div>
<div class="paragraph">
<p>Now create the following file at <code>src/test/kotlin/io/confluent/developer/RunningAverageTest.kt</code>.
Testing a Kafka streams application requires a bit of test harness code, but happily the <code>org.apache.kafka.streams.TopologyTestDriver</code> class makes this much more pleasant that it would otherwise be.</p>
</div>
<div class="paragraph">
<p>There is a <code>validateAverageRating()</code> method in <code>RunningAverageTest</code> annotated with <code><a href="https://github.com/Test">@Test</a></code>.
This method actually runs our Streams topology using the <code>TopologyTestDriver</code> and some mocked data that is set up inside the test method.</p>
</div>
<div class="listingblock">
<div class="title">RunningAverageTest.kt</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-kotlin hljs" data-lang="kotlin">import io.confluent.developer.kstreams.*
import io.confluent.kafka.streams.serdes.json.KafkaJsonSchemaSerde
import org.apache.kafka.common.serialization.DoubleDeserializer
import org.apache.kafka.common.serialization.LongDeserializer
import org.apache.kafka.common.serialization.LongSerializer
import org.apache.kafka.streams.*
import org.apache.kafka.streams.kstream.KStream
import org.apache.kafka.streams.state.KeyValueStore
import org.hamcrest.CoreMatchers
import org.hamcrest.MatcherAssert
import org.junit.After
import org.junit.Assert
import org.junit.Before
import org.junit.Test
import java.util.*

class RunningAverageTest {
    private lateinit var testDriver: TopologyTestDriver
    private var ratingSpecificAvroSerde: KafkaJsonSchemaSerde&lt;Rating&gt;? = null

    @Before
    fun setUp() {
        val mockProps = Properties()
        mockProps["application.id"] = "kafka-movies-test"
        mockProps["bootstrap.servers"] = "DUMMY_KAFKA_CONFLUENT_CLOUD_9092"
        mockProps["schema.registry.url"] = "mock://DUMMY_SR_CONFLUENT_CLOUD_8080"

        val builder = StreamsBuilder()
        val countAndSumSerde: KafkaJsonSchemaSerde&lt;CountAndSum&gt; = jsonSchemaSerde(mockProps, false)
        ratingSpecificAvroSerde = jsonSchemaSerde(mockProps, false)

        val ratingStream: KStream&lt;Long, Rating&gt; = ratingsStream(builder, mockProps)

        getRatingAverageTable(
            ratingStream,
            AVERAGE_RATINGS_TOPIC_NAME,
            countAndSumSerde
        )
        val topology = builder.build()
        testDriver = TopologyTestDriver(topology, mockProps)
    }

    @Test
    fun validateIfTestDriverCreated() {
        Assert.assertNotNull(testDriver)
    }

    @Test
    fun validateAverageRating() {
        val inputTopic: TestInputTopic&lt;Long, Rating&gt; = testDriver.createInputTopic(
            RATINGS_TOPIC_NAME,
            LongSerializer(),
            ratingSpecificAvroSerde?.serializer()
        )
        inputTopic.pipeKeyValueList(
            listOf(
                KeyValue(LETHAL_WEAPON_RATING_8.movieId, LETHAL_WEAPON_RATING_8),
                KeyValue(LETHAL_WEAPON_RATING_10.movieId, LETHAL_WEAPON_RATING_10)
            )
        )
        val outputTopic: TestOutputTopic&lt;Long, Double&gt; = testDriver.createOutputTopic(
            AVERAGE_RATINGS_TOPIC_NAME,
            LongDeserializer(),
            DoubleDeserializer()
        )
        val keyValues: List&lt;KeyValue&lt;Long, Double&gt;&gt; = outputTopic.readKeyValuesToList()
        // I sent two records to input topic
        // I expect second record in topic will contain correct result
        val longDoubleKeyValue = keyValues[1]
        println("longDoubleKeyValue = $longDoubleKeyValue")
        MatcherAssert.assertThat(
            longDoubleKeyValue,
            CoreMatchers.equalTo(KeyValue(362L, 9.0))
        )
        val keyValueStore: KeyValueStore&lt;Long, Double&gt; = testDriver.getKeyValueStore("average-ratings")
        val expected = keyValueStore[362L]
        Assert.assertEquals("Message", expected, 9.0, 0.0)
    }

    @After
    fun tearDown() {
        testDriver.close()
    }

    companion object {
        private const val RATINGS_TOPIC_NAME = "ratings"
        private const val AVERAGE_RATINGS_TOPIC_NAME = "average-ratings"
        private val LETHAL_WEAPON_RATING_10 = Rating(362L, 10.0)
        private val LETHAL_WEAPON_RATING_8 = Rating(362L, 8.0)
    }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="infrastructure"><a class="anchor" href="#infrastructure"></a>Infrastructure</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="title">docker-compose.yml</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">version: '2'

services:
zookeeper:
image: confluentinc/cp-zookeeper:6.0.0
hostname: zookeeper
container_name: zookeeper
ports:
- "2181:2181"
environment:
ZOOKEEPER_CLIENT_PORT: 2181
ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:6.0.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR

  schema-registry:
    image: confluentinc/cp-schema-registry:6.0.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:9092'
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: WARN</code></pre>
</div>
</div>
</div>
</div></div></div><footer class="entry-footer"><div class="tags"><span class="title">tags: </span></div></footer><div id="comments">
            <div id="disqus_thread"></div>
            <script type="text/javascript">
            var disqus_shortname = 'nextjavaheadbraincom';
            var disqus_url = "http://gamov.io/workshop/2021/03/30/ktor-kafka-2021.html";
            var disqus_developer = null;
            var disqus_identifier = null;
            (function() {
              var dsq = document.createElement("script"); dsq.type = "text/javascript"; dsq.async = true;
              dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
              (document.getElementsByTagName("head")[0] || document.getElementsByTagName("body")[0]).appendChild(dsq);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript=nextjavaheadbraincom">comments powered by Disqus.</a></noscript>
          </div></article></div></div></body></html><div id="copyright"><div class="row full-width"><div class="large-4 columns"><p>© Viktor Gamov 2021—2007</p></div><div class="large-8 columns"><ul class="inline-list right"><li><a href="https://github.com/gamussa" target="_blank"><span class="icon"><i class="fa fa-github"></i></span>&nbspGithub</a></li><li class="divider"></li><li><a href="https://twitter.com/gamussa" target="_blank"><span class="icon"><i class="fa fa-twitter"></i></span>&nbspTwitter</a></li><li class="divider"></li></ul></div></div></div><script>document.write('<script src=' + ('__proto__' in {} ? '/javascripts/vendor/zepto' : '/javascripts/vendor/jquery') + '.js><\/script>')</script><script src="/javascripts/foundation/foundation.js"><script src="/javascripts/foundation/foundation.topbar.js"></script></script><script>$(document).foundation();</script><script src="/javascripts/vendor/highlight.min.js"></script><script>$(hljs.initHighlighting());</script><script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount','UA-40354726-1']);
_gaq.push(['_trackPageview']);
(function() {
 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
 ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>
<!--End Footer-->